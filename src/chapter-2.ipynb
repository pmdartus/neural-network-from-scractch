{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neurons & Layer\n",
    "\n",
    "Coding by hand an artifical neural network by hand. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [0.3, 0.5, 0.2]\n",
    "weights = [\n",
    "    [0.5, 0.2, 0.8],\n",
    "    [0.2, 0.3, 0.1],\n",
    "    [0.1, 0.4, 0.9]\n",
    "]\n",
    "baises = [0.3, 0.1, 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.71, 0.32999999999999996, 0.71]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout_outputs = []\n",
    "\n",
    "for neuron_weigths, neron_bais in zip(weights, baises):\n",
    "    # Init output\n",
    "    output = 0\n",
    "    # Add invidual input multiplied by the respective weigth\n",
    "    for input, weight in zip(inputs, neuron_weigths):\n",
    "        output += input * weight\n",
    "    # Add bais to current output.\n",
    "    output += neron_bais\n",
    "    # Add output to layer.\n",
    "    layout_outputs.append(output)\n",
    "\n",
    "layout_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "\n",
    "A **tensor** is an object that can be represented as an array.\n",
    "\n",
    "An **array** is an ordered homologous number container. It can be of `n` dimensions. When, `n=1` we speak about 1-D array (or a list). When, `n=2` we refer to this as a matrix (not all arrays are matrices).\n",
    "\n",
    "**Homologous** is a array property defining that number of items on each dimension should be identical. The following matrix isn't homologous because the shape isn't consistent.\n",
    "\n",
    "```py\n",
    "[\n",
    "    [1,2,3],\n",
    "    [4,5]\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuron with Numpy\n",
    "\n",
    "Using dot product between vectors to achieve the same thing in a more performant way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.array([0.3, 0.5, 0.2])\n",
    "weights = np.array([0.5, 0.2, 0.8])\n",
    "bais = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2.41)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = np.dot(inputs, weights) + bais\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuron layers\n",
    "\n",
    "The same approach can also be used for network layers thanks to `numpy`. We are effectively passing a matrix (2D) as first argument and a vector a second argument (1D). `numpy` treats the matrix as a list of vectors and run the dot product against the second argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [0.3, 0.5, 0.2, 0.7]\n",
    "weights = [\n",
    "    [0.5, 0.2, 0.8, 0.4],\n",
    "    [0.2, 0.3, 0.1, 0.1],\n",
    "    [0.1, 0.4, 0.9, 0.5]\n",
    "]\n",
    "baises = [0.3, 0.1, 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99, 0.4 , 1.06])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = np.dot(weights, inputs) + baises\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix transposition\n",
    "\n",
    "Transposition flips the dimension of a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2, 3]\n",
    "b = [2, 3, 4]\n",
    "\n",
    "a = np.array([a])\n",
    "b = np.array([b]).T\n",
    "\n",
    "np.dot(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batching\n",
    "\n",
    "Instead of processing one input at the time, we can speed things up by passing batch of inputs and have them processed all at once.\n",
    "\n",
    "Each row (or vector) in the `inputs` can be treated as a sample. For the dot product to happen, we need transpose the `weights` matrix. Matrix multiplactions applies only when left matrix has the same number of column as number of rows on the right matrix: \n",
    "* Left matrix shape: `(2, 3)`, Right matrix shape `(4, 3)`: Not OK\n",
    "* Left matrix shape: `(2, 3)`, Right matrix shape `(3, 4)`: OK -> Resulting matrix shape: `(2, 4)`\n",
    "\n",
    "Because of this, the number of samples part of the input can be increased without impacting the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.array([\n",
    "    [0.3, 0.5, 0.2, 0.7],\n",
    "    [0.2, 0.6, 0.1, 0.7]\n",
    "])\n",
    "weights = np.array([\n",
    "    [0.5, 0.2, 0.8, 0.4],\n",
    "    [0.2, 0.3, 0.1, 0.1],\n",
    "    [0.1, 0.4, 0.9, 0.5]\n",
    "])\n",
    "baises = np.array([0.3, 0.1, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99, 0.4 , 1.06],\n",
       "       [0.88, 0.4 , 1.  ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(inputs, weights.T) + baises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the reason why deep neural network always accepts and list of inputs and generate a list of predictions, even when a single prediction is needed. This is because the layers have been designed for performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
